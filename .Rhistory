if(flag)
{
next
}
neigh.grid.ind = floor((hash - 1) / nset) + 1
j = hash %% nset #which kind of dataset
if(j==0)
j=nset
tmp.mix.mat = cbind(mix.mat, mix.mat.list[[j]][neigh.grid.ind,] )
colnames(tmp.mix.mat) = c(names,paste('X',(neigh.grid.ind-1) * nset + j,sep=''))
cat("hash value: ",hash,"\n")
var.model = VAR(tmp.mix.mat,p=4,type="const")
#get the p-value
granger.test = causality(var.model,cause = paste('X',(neigh.grid.ind-1) * nset + j,sep=''))$Granger
#if pass the test, update the cluster status
if(granger.test$p.value < 0.05){#reject the null hypothesis that there is no causality
mix.mat = tmp.mix.mat
names = colnames(mix.mat)
cluster.vec = c(cluster.vec, hash)
}
}
clusters[[ncluster]] = cluster.vec
ncluster = ncluster+1
visit.sets = c(visit.sets,cluster.vec)
}
return (clusters)
}
debugSource('~/CodeSpace/R/crowd_stream/VARCluster.r')
clist = cluster.datasets(2)
flag
debugSource('~/CodeSpace/R/crowd_stream/VARCluster.r')
clist = cluster.datasets(2)
neighbor.hashs
self.hash
neighbor.hashs
self.hash
class(neighbor.hashs)
neighbor.hash[1]
neighbor.hashs[1]
neighbor.hashs[-7]
neighbor.hashs[ -which(neighbor.hashs==self.hash) ]
which(neighbor.hashs==self.hash)
which(neighbor.hashs == self.hash)
which(neighbor.hashs = self.hash)
which(neighbor.hashs == self.hash)
which(neighbor.hashs == 8)
which(neighbor.hashs == 7)
which(neighbor.hashs == self.hash)
self.hash
class(self.hash)
self.hash
which(neighbor.hashs == 4)
which(neighbor.hashs == 3)
neighbor.hashs
which(neighbor.hashs == 7)
which(neighbor.hashs == 4)
which(neighbor.hashs == 8)
which(neighbor.hashs == 9)
which(neighbor.hashs == 10)
which(neighbor.hashs == 23)
which(neighbor.hashs == 12)
which(neighbor.hashs == 4)
which(neighbor.hashs == 5)
which(neighbor.hashs == 6)
neighbor.hashs[7]
neighbor.hashs[8]
neighbor.hashs[9]
neighbor.hashs[9] == 6
all.equals(neighbor.hashs[9], 6)
all.equal(neighbor.hashs[9], 6)
grid.ind
k
debugSource('~/CodeSpace/R/crowd_stream/VARCluster.r')
debugSource('~/CodeSpace/R/crowd_stream/VARCluster.r')
neighbor(2,1)
hash.dataset
which(hash.dataset == 6)
which(hash.dataset == 5)
which(hash.dataset == 11)
length(hash.dataset)
hash.dataset[9]
which(hash.dataset == 6)
neighbor <- function(grid.ind, k){
hash.dataset = c()
row = (grid.ind-1) / ngrid.col + 1
col = grid.ind %% ngrid.col
r.offset = c(0,0,0,1,-1)
c.offset = c(0,1,-1,0,0)
for(i in 1:5){
r = row + r.offset[i]
c = col + c.offset[i]
if(r<=ngrid.row && r>=1 && c>=1 && c<=ngrid.col){
n.grid.ind = (r-1) * ngrid.col + c
hash.beg =  (n.grid.ind - 1) * nset + 1
hash.end = hash.beg + nset - 1
for(h in hash.beg:hash.end)
hash.dataset = append(hash.dataset,h)
}
}
return (hash.dataset)
}
debugSource('~/CodeSpace/R/crowd_stream/VARCluster.r')
neighbor(2,1)
hash.dataset[9]
hash.dataset
which(hash.dataset == 17)
which(hash.dataset == 7)
debugSource('~/CodeSpace/R/crowd_stream/VARCluster.r')
neighbor(2,1)
neighbor <- function(grid.ind, k){
hash.dataset = c()
row = (grid.ind-1) / ngrid.col + 1
col = grid.ind %% ngrid.col
r.offset = c(0,0,0,1,-1)
c.offset = c(0,1,-1,0,0)
for(i in 1:5){
r = row + r.offset[i]
c = col + c.offset[i]
if(r<=ngrid.row && r>=1 && c>=1 && c<=ngrid.col){
n.grid.ind = (r-1) * ngrid.col + c
hash.beg =  (n.grid.ind - 1) * nset + 1
hash.end = hash.beg + nset - 1
for(h in hash.beg:hash.end)
if(h == 18)
print(h)
hash.dataset = append(hash.dataset,h)
}
}
return (hash.dataset)
}
neighbor(2,1)
neighbor <- function(grid.ind, k){
hash.dataset = c()
row = (grid.ind-1) / ngrid.col + 1
col = grid.ind %% ngrid.col
r.offset = c(0,0,0,1,-1)
c.offset = c(0,1,-1,0,0)
for(i in 1:5){
r = row + r.offset[i]
c = col + c.offset[i]
if(r<=ngrid.row && r>=1 && c>=1 && c<=ngrid.col){
n.grid.ind = (r-1) * ngrid.col + c
hash.beg =  (n.grid.ind - 1) * nset + 1
hash.end = hash.beg + nset - 1
for(h in hash.beg:hash.end)
{
if(h == 18)
print(h)
hash.dataset = append(hash.dataset,h)
}
}
}
return (hash.dataset)
}
neighbor(2,1)
neighbor <- function(grid.ind, k){
hash.dataset = c()
row = (grid.ind-1) / ngrid.col + 1
col = grid.ind %% ngrid.col
r.offset = c(0,0,0,1,-1)
c.offset = c(0,1,-1,0,0)
for(i in 1:5){
r = row + r.offset[i]
c = col + c.offset[i]
if(r<=ngrid.row && r>=1 && c>=1 && c<=ngrid.col){
n.grid.ind = (r-1) * ngrid.col + c
hash.beg =  (n.grid.ind - 1) * nset + 1
hash.end = hash.beg + nset - 1
for(h in hash.beg:hash.end)
{
if(h == 18)
cat('h',h,'\n')
hash.dataset = append(hash.dataset,h)
}
}
}
return (hash.dataset)
}
neighbor(2,1)
debugSource('~/CodeSpace/R/crowd_stream/VARCluster.r')
neighbor <- function(grid.ind, k){
hash.dataset = c()
row = (grid.ind-1) / ngrid.col + 1
col = grid.ind %% ngrid.col
r.offset = c(0,0,0,1,-1)
c.offset = c(0,1,-1,0,0)
for(i in 1:5){
r = row + r.offset[i]
c = col + c.offset[i]
if(r<=ngrid.row && r>=1 && c>=1 && c<=ngrid.col){
n.grid.ind = (r-1) * ngrid.col + c
hash.beg =  (n.grid.ind - 1) * nset + 1
hash.end = hash.beg + nset - 1
for(h in hash.beg:hash.end)
{
hash.dataset = append(hash.dataset,h)
}
}
}
return (hash.dataset)
}
debugSource('~/CodeSpace/R/crowd_stream/VARCluster.r')
neighbor(2,1)
is.integer(h)
debugSource('~/CodeSpace/R/crowd_stream/VARCluster.r')
neighbor(2,1)
is.integer(h)
h
hash.end
h
is.integer(h)
h
is.integer(h)
h
is.integer(h)
is.integer(h)
is.integer(h)
h
is.integer(h)
h
hash.beg
is.integer(hash.beg)
is.integer(n.grid.ind)
is.integer(r)
is.integer(c)
is.integer(row)
neighbor <- function(grid.ind, k){
hash.dataset = c()
row = (grid.ind-1) / ngrid.col + 1
col = grid.ind %% ngrid.col
r.offset = c(0,0,0,1,-1)
c.offset = c(0,1,-1,0,0)
for(i in 1:5){
r = row + r.offset[i]
c = col + c.offset[i]
if(r<=ngrid.row && r>=1 && c>=1 && c<=ngrid.col){
n.grid.ind = (r-1) * ngrid.col + c
hash.beg =  (n.grid.ind - 1) * nset + 1
hash.end = hash.beg + nset - 1
hash.dataset = c(hash.dataset,hash.beg:hash.end)
}
}
return (hash.dataset)
}
neighbor(2,1)
debugSource('~/CodeSpace/R/crowd_stream/VARCluster.r')
neighbor(2,1)
is.integer(row)
is.integer(grid.ind)
row
neighbor <- function(grid.ind, k){
hash.dataset = c()
row = floor((grid.ind-1) / ngrid.col) + 1
col = grid.ind %% ngrid.col
r.offset = c(0,0,0,1,-1)
c.offset = c(0,1,-1,0,0)
for(i in 1:5){
r = row + r.offset[i]
c = col + c.offset[i]
if(r<=ngrid.row && r>=1 && c>=1 && c<=ngrid.col){
n.grid.ind = (r-1) * ngrid.col + c
hash.beg =  (n.grid.ind - 1) * nset + 1
hash.end = hash.beg + nset - 1
hash.dataset = c(hash.dataset,hash.beg:hash.end)
}
}
return (hash.dataset)
}
debugSource('~/CodeSpace/R/crowd_stream/VARCluster.r')
neighbor <- function(grid.ind, k){
hash.dataset = c()
row = floor((grid.ind-1) / ngrid.col) + 1
col = grid.ind %% ngrid.col
r.offset = c(0,0,0,1,-1)
c.offset = c(0,1,-1,0,0)
for(i in 1:5){
r = row + r.offset[i]
c = col + c.offset[i]
if(r<=ngrid.row && r>=1 && c>=1 && c<=ngrid.col){
n.grid.ind = (r-1) * ngrid.col + c
hash.beg =  (n.grid.ind - 1) * nset + 1
hash.end = hash.beg + nset - 1
hash.dataset = c(hash.dataset,hash.beg:hash.end)
}
}
return (hash.dataset)
}
debugSource('~/CodeSpace/R/crowd_stream/VARCluster.r')
neighbor(2,1)
is.integer(row)
row
col
is.integer(col)
is.integer(grid.ind)
neighbor <- function(grid.ind, k){
hash.dataset = c()
row = floor((grid.ind-1) / ngrid.col) + 1
col = grid.ind %% ngrid.col
r.offset = c(0,0,0,1,-1)
c.offset = c(0,1,-1,0,0)
for(i in 1:5){
r = row + r.offset[i]
c = col + c.offset[i]
if(r<=ngrid.row && r>=1 && c>=1 && c<=ngrid.col){
n.grid.ind = (r-1) * ngrid.col + c
hash.beg =  (n.grid.ind - 1) * nset + 1
hash.end = hash.beg + nset - 1
hash.dataset = c(hash.dataset,hash.beg:hash.end)
}
}
return (hash.dataset)
}
debugSource('~/CodeSpace/R/crowd_stream/VARCluster.r')
neighbor(2,1)
hash.dataset
which(hash.dataset == 15)
neighbor <- function(grid.ind, k){
hash.dataset = c()
row = floor((grid.ind-1) / ngrid.col) + 1
col = grid.ind %% ngrid.col
r.offset = c(0,0,0,1,-1)
c.offset = c(0,1,-1,0,0)
for(i in 1:5){
r = row + r.offset[i]
c = col + c.offset[i]
if(r<=ngrid.row && r>=1 && c>=1 && c<=ngrid.col){
n.grid.ind = (r-1) * ngrid.col + c
hash.beg =  (n.grid.ind - 1) * nset + 1
hash.end = hash.beg + nset - 1
hash.dataset = c(hash.dataset,hash.beg:hash.end)
}
}
self.hash = (grid.ind-1) * nset + k
hash.dataset = hash.dataset[ -which(hash.dataset == self.hash)]
return (hash.dataset)
}
neighbor(2,1)
neighbor(4,2)
neighbor(5,2)
cluster.datasets <- function(grid.ind){
ncluster = 1
clusters = list()
visit.sets = c()
#use twitter as the first sub dataset
for(k in 1:nset){
#check whether this dataset has been visited
self.hash = k + (grid.ind-1) * nset
if(is.element(self.hash, visit.sets))
next
cat("self.hash:",self.hash,"\n")
neighbor.hashs = neighbor(grid.ind, k)
cluster.vec = c(self.hash)#the vector store all the sub dataset indices
mix.mat = data.matrix(data.frame(mix.mat.list[[k]][grid.ind,]))
names = c(paste('X',(grid.ind-1) * nset + k,sep=''))
colnames(mix.mat) = names
#test all the other sub datasets
for(hash in neighbor.hashs){
neigh.grid.ind = floor((hash - 1) / nset) + 1
j = hash %% nset #which kind of dataset
if(j==0)
j=nset
tmp.mix.mat = cbind(mix.mat, mix.mat.list[[j]][neigh.grid.ind,] )
colnames(tmp.mix.mat) = c(names,paste('X',(neigh.grid.ind-1) * nset + j,sep=''))
cat("hash value: ",hash,"\n")
var.model = VAR(tmp.mix.mat,p=4,type="const")
#get the p-value
granger.test = causality(var.model,cause = paste('X',(neigh.grid.ind-1) * nset + j,sep=''))$Granger
#if pass the test, update the cluster status
if(granger.test$p.value < 0.05){#reject the null hypothesis that there is no causality
mix.mat = tmp.mix.mat
names = colnames(mix.mat)
cluster.vec = c(cluster.vec, hash)
}
}
clusters[[ncluster]] = cluster.vec
ncluster = ncluster+1
visit.sets = c(visit.sets,cluster.vec)
}
return (clusters)
}
cluster.datasets(2)
cluster.datasets(4)
cluster.datasets(9)
cluster.datasets(10)
cluster.datasets(6)
cluster.datasets(5)
cluster.datasets(4)
cluster.datasets(11)
cluster.datasets(12)
cluster.datasets(13)
cluster.datasets(14)
cluster.datasets(15)
debugSource('~/CodeSpace/R/crowd_stream/VARCluster.r')
cluster.datasets(15)
neighbor.hashs
cluster.datasets(15)
hash.dataseet
hash.dataset
grid.ind
k
neighbor(15,1)
hash.dataset
neighbor(15,1)
neighbor <- function(grid.ind, k){
hash.dataset = c()
row = floor((grid.ind-1) / ngrid.col) + 1
col = grid.ind %% ngrid.col
if(col == 0)
col = ngrid.col
r.offset = c(0,0,0,1,-1)
c.offset = c(0,1,-1,0,0)
for(i in 1:5){
r = row + r.offset[i]
c = col + c.offset[i]
if(r<=ngrid.row && r>=1 && c>=1 && c<=ngrid.col){
n.grid.ind = (r-1) * ngrid.col + c
hash.beg =  (n.grid.ind - 1) * nset + 1
hash.end = hash.beg + nset - 1
hash.dataset = c(hash.dataset,hash.beg:hash.end)
}
}
self.hash = (grid.ind-1) * nset + k
hash.dataset = hash.dataset[ -which(hash.dataset == self.hash)]
return (hash.dataset)
}
#Cluster the datasets in or near the grids[grid.ind]
#We hash the cluster result by setting value = (grid.ind-1) * nset + i, so 4 = 1 * 3 + 1 means the no.1 dataset in grid 1.
cluster.datasets <- function(grid.ind){
ncluster = 1
clusters = list()
visit.sets = c()
#use twitter as the first sub dataset
for(k in 1:nset){
#check whether this dataset has been visited
self.hash = k + (grid.ind-1) * nset
if(is.element(self.hash, visit.sets))
next
cat("self.hash:",self.hash,"\n")
neighbor.hashs = neighbor(grid.ind, k)
cluster.vec = c(self.hash)#the vector store all the sub dataset indices
mix.mat = data.matrix(data.frame(mix.mat.list[[k]][grid.ind,]))
names = c(paste('X',(grid.ind-1) * nset + k,sep=''))
colnames(mix.mat) = names
#test all the other sub datasets
for(hash in neighbor.hashs){
neigh.grid.ind = floor((hash - 1) / nset) + 1
j = hash %% nset #which kind of dataset
if(j==0)
j=nset
tmp.mix.mat = cbind(mix.mat, mix.mat.list[[j]][neigh.grid.ind,] )
colnames(tmp.mix.mat) = c(names,paste('X',(neigh.grid.ind-1) * nset + j,sep=''))
cat("hash value: ",hash,"\n")
var.model = VAR(tmp.mix.mat,p=4,type="const")
#get the p-value
granger.test = causality(var.model,cause = paste('X',(neigh.grid.ind-1) * nset + j,sep=''))$Granger
#if pass the test, update the cluster status
if(granger.test$p.value < 0.05){#reject the null hypothesis that there is no causality
mix.mat = tmp.mix.mat
names = colnames(mix.mat)
cluster.vec = c(cluster.vec, hash)
}
}
clusters[[ncluster]] = cluster.vec
ncluster = ncluster+1
visit.sets = c(visit.sets,cluster.vec)
}
return (clusters)
}
cluster.datasets(4)
cluster.datasets(5)
cluster.datasets(6)
cluster.datasets <- function(grid.ind){
ncluster = 1
clusters = list()
visit.sets = c()
#use twitter as the first sub dataset
for(k in 1:nset){
#check whether this dataset has been visited
self.hash = k + (grid.ind-1) * nset
if(is.element(self.hash, visit.sets))
next
#cat("self.hash:",self.hash,"\n")
neighbor.hashs = neighbor(grid.ind, k)
cluster.vec = c(self.hash)#the vector store all the sub dataset indices
mix.mat = data.matrix(data.frame(mix.mat.list[[k]][grid.ind,]))
names = c(paste('X',(grid.ind-1) * nset + k,sep=''))
colnames(mix.mat) = names
#test all the other sub datasets
for(hash in neighbor.hashs){
neigh.grid.ind = floor((hash - 1) / nset) + 1
j = hash %% nset #which kind of dataset
if(j==0)
j=nset
tmp.mix.mat = cbind(mix.mat, mix.mat.list[[j]][neigh.grid.ind,] )
colnames(tmp.mix.mat) = c(names,paste('X',(neigh.grid.ind-1) * nset + j,sep=''))
#cat("hash value: ",hash,"\n")
var.model = VAR(tmp.mix.mat,p=4,type="const")
#get the p-value
granger.test = causality(var.model,cause = paste('X',(neigh.grid.ind-1) * nset + j,sep=''))$Granger
#if pass the test, update the cluster status
if(granger.test$p.value < 0.05){#reject the null hypothesis that there is no causality
mix.mat = tmp.mix.mat
names = colnames(mix.mat)
cluster.vec = c(cluster.vec, hash)
}
}
clusters[[ncluster]] = cluster.vec
ncluster = ncluster+1
visit.sets = c(visit.sets,cluster.vec)
}
return (clusters)
}
